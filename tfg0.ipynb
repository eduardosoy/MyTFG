{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os, shutil, pathlib\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Variables globales del sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_dir = pathlib.Path(\"DatasetOriginal/Image Data Base\")\n",
    "new_base_dir = pathlib.Path(\"TFGDataset\")\n",
    "content = os.listdir(original_dir)\n",
    "BATCH_SIZE = 64\n",
    "size_x = 256\n",
    "size_y = 256"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Función para contar imágenes por categorías"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def contando_categorias():\n",
    "    counter_more200 = 0\n",
    "    counter_less200 = 0\n",
    "    categories = {}\n",
    "    for category in content:\n",
    "        counter = 0\n",
    "        for path in pathlib.Path(original_dir / category).iterdir():   \n",
    "            counter += 1\n",
    "        if counter < 200:\n",
    "            counter_less200 += 1\n",
    "            categories.update({str(category):counter})\n",
    "            \n",
    "        else:\n",
    "            counter_more200 += 1\n",
    "    print(\"Hay \"+ str(counter_more200) + \" categorias con más de 200 ejemplos\")\n",
    "    print(\"Hay \"+ str(counter_less200) + \" categorias con menos de 200 ejemplos\")\n",
    "    return categories\n",
    "        \n",
    "categories = contando_categorias()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(categories)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Función para crear carpetas de subconjuntos de datos a partir de un dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_subsets(proportion, max_data):\n",
    "    for category in content:\n",
    "        fnames = []\n",
    "        count = 1\n",
    "        for path in (original_dir / category).iterdir():\n",
    "            fnames.append(os.path.basename(path))\n",
    "            count += 1\n",
    "        leftover = count % 10\n",
    "        data = count - leftover\n",
    "        data = min(data, max_data)\n",
    "        primero = int(data * proportion[0])\n",
    "        segundo = int(data * proportion[1]) + primero\n",
    "        tercero = int(data * proportion[2]) + segundo\n",
    "        train = fnames[0:primero]\n",
    "        validation = fnames[primero:segundo]\n",
    "        test = fnames[segundo:tercero]\n",
    "        if data < 200 and leftover > 0:\n",
    "            train.extend(fnames[tercero:count - 1])\n",
    "        classification = {\"train\": train, \"validation\": validation, \"test\": test}\n",
    "        for subset in [\"train\", \"validation\", \"test\"]:\n",
    "            dir = new_base_dir / subset / category\n",
    "            os.makedirs(dir)\n",
    "            count = 1\n",
    "            for fname in classification[subset]:\n",
    "                file = str(count) + '.jpg'\n",
    "                try:\n",
    "                    shutil.copyfile(src=original_dir / category / fname, dst=dir / file)\n",
    "                    count += 1\n",
    "                except:\n",
    "                    print(\"error\")\n",
    "                    \n",
    "                    \n",
    "proportion = [0.8, 0.1, 0.1] #Para dividir los datos en conjuntos de estas proporciones\n",
    "make_subsets(proportion, 200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creación de los datasets específicos a partir de las carpetas "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=(size_x, size_y),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical')\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=(size_x, size_y),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical')\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(size_x, size_y),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comprobación de que está todo en orden y muestreo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " for data_batch, labels_batch in train_dataset:\n",
    "    print(\"data batch shape:\", data_batch.shape)\n",
    "    print(\"labels batch shape:\", labels_batch.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 13))\n",
    "class_names = train_dataset.class_names\n",
    "for images, labels in train_dataset.take(2):\n",
    "    for i in range(3):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        arr = labels[i].numpy()\n",
    "        tuple = np.where(arr == 1)\n",
    "        plt.title(class_names[tuple[0][0]])\n",
    "        plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo creado desde cero"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(size_x, size_y, 3)) \n",
    "x = layers.Rescaling(1./255)(inputs) \n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=512, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(58, activation=\"softmax\")(x)\n",
    "model0 = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model0.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entrenamiento y guardado de resultados del modelo cero"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callbacks = [\n",
    " keras.callbacks.ModelCheckpoint(\n",
    " filepath=\"model0/best_version\",\n",
    " save_best_only=True,\n",
    " monitor=\"val_loss\")\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model0.compile(loss=\"categorical_crossentropy\",\n",
    " optimizer=\"rmsprop\",\n",
    " metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model0.fit(\n",
    " train_dataset,\n",
    " epochs=30,\n",
    " validation_data=validation_dataset,\n",
    " callbacks=callbacks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model0.save('model0/model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save('model0/history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Análisis de resultados"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_model = load_model('model0/model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_history=np.load('model0/history.npy',allow_pickle='TRUE').item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss = my_history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = my_history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model0/model')\n",
    "results= model.evaluate(test_dataset)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model0/best_version')\n",
    "results= model.evaluate(test_dataset)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}